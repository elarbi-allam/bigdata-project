# ğŸŒ¡ï¸ Projet Big Data - Monitoring IoT de TempÃ©rature en Temps RÃ©el

> **Ã‰tudiant :** ELARBI ALLAM  
> **Ã‰tablissement :** ENSA  
> **AnnÃ©e Universitaire :** 2025-2026  
> **Encadrant :** Professeur Hassan BADIR

---

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'Ensemble](#vue-densemble)
- [Architecture Technique](#architecture-technique)
- [Technologies UtilisÃ©es](#technologies-utilisÃ©es)
- [Installation et Configuration](#installation-et-configuration)
- [ExÃ©cution du Projet](#exÃ©cution-du-projet)
- [RÃ©sultats](#rÃ©sultats)
- [Structure du Projet](#structure-du-projet)

---

## ğŸ¯ Vue d'Ensemble

Ce projet implÃ©mente un **pipeline Big Data complet** pour le monitoring en temps rÃ©el de capteurs IoT de tempÃ©rature, utilisant les technologies Apache Kafka, Spark Streaming et HDFS dans un environnement containerisÃ© Docker.

### Objectifs

âœ… Ingestion de donnÃ©es IoT en temps rÃ©el avec **Apache Kafka**  
âœ… Traitement streaming avec **Apache Spark Streaming**  
âœ… Stockage distribuÃ© avec **HDFS** (format Parquet)  
âœ… AgrÃ©gations par fenÃªtres temporelles  
âœ… Analyse statistique et gÃ©nÃ©ration de rapports  

### Cas d'Usage

**Monitoring de tempÃ©rature** dans 6 villes marocaines (Casablanca, Rabat, Marrakech, FÃ¨s, Tanger, Agadir) via 20 capteurs IoT simulÃ©s gÃ©nÃ©rant des mesures de tempÃ©rature et d'humiditÃ© toutes les secondes.

---

## ğŸ—ï¸ Architecture Technique
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE BIG DATA IoT                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  ğŸ“¡ Producteur Python (20 capteurs IoT)                     â”‚
â”‚      â†“                                                      â”‚
â”‚  ğŸ”„ Apache Kafka (Topic: iot-temperature)                   â”‚
â”‚      â†“                                                      â”‚
â”‚  âš¡ Apache Spark Streaming (Mode Local)                     â”‚
â”‚      â”œâ”€ Console (Affichage temps rÃ©el)                     â”‚
â”‚      â””â”€ HDFS (Stockage Parquet)                            â”‚
â”‚      â†“                                                      â”‚
â”‚  ğŸ’¾ HDFS (/tmp/iot-data/raw/*.parquet)                      â”‚
â”‚      â†“                                                      â”‚
â”‚  ğŸ“Š Analyse Spark SQL (Statistiques & Alertes)             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants du Cluster Docker

| Conteneur | RÃ´le | Ports |
|-----------|------|-------|
| **zookeeper** | Coordination Kafka | 2181 |
| **kafka** | Message Broker | 9092 |
| **spark-master** | NÅ“ud MaÃ®tre Spark | 8080, 7077, 4040 |
| **spark-worker** | NÅ“ud Worker Spark | - |
| **namenode** | HDFS NameNode | 9870, 9000 |
| **datanode** | HDFS DataNode | - |

---

## ğŸ› ï¸ Technologies UtilisÃ©es

### Big Data Stack

- **Apache Kafka 7.5.0** - Ingestion streaming
- **Apache Spark 3.5.0** - Traitement distribuÃ©
- **Apache Hadoop 3.2.1** - Stockage HDFS
- **Apache Zookeeper 7.5.0** - Coordination

### DÃ©veloppement

- **Python 3.x** - Scripts producteur/analyse
- **Docker & Docker Compose** - Containerisation
- **kafka-python** - Client Kafka Python

### Formats de DonnÃ©es

- **JSON** - Format des messages Kafka
- **Parquet + Snappy** - Stockage compressÃ© HDFS

---

## ğŸ“¦ Installation et Configuration

### PrÃ©requis

- Docker Desktop installÃ© et dÃ©marrÃ©
- Python 3.x avec pip
- 8 GB RAM minimum
- 20 GB espace disque

### Ã‰tape 1 : Cloner le Projet
```bash
git clone https://github.com/elarbi-allam/bigdata-project.git
cd bigdata-project
```

### Ã‰tape 2 : DÃ©marrer l'Infrastructure Docker
```powershell
# DÃ©marrer tous les conteneurs
docker-compose up -d

# VÃ©rifier le statut
docker-compose ps
```

**RÃ©sultat attendu :** Tous les conteneurs doivent Ãªtre **Up**

### Ã‰tape 3 : Installer les DÃ©pendances
```powershell
# Installer kafka-python dans Spark
docker exec -it -u root spark-master pip install kafka-python

# Fixer les permissions Ivy (pour Spark)
docker exec -it -u root spark-master bash -c "mkdir -p /home/spark/.ivy2/cache /home/spark/.ivy2/jars && chown -R spark:spark /home/spark/.ivy2 && chmod -R 777 /home/spark/.ivy2"
```

### Ã‰tape 4 : CrÃ©er le Topic Kafka
```powershell
docker exec -it kafka kafka-topics --create --topic iot-temperature --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
```

---

## ğŸš€ ExÃ©cution du Projet

### Terminal 1 : Lancer le Producteur IoT
```powershell
docker exec -it spark-master python3 /opt/spark-apps/producer.py
```

**Sortie attendue :**
```
============================================================
ğŸŒ¡ï¸  PRODUCTEUR IoT - DÃ‰MARRAGE
============================================================
ğŸ“ Villes : Casablanca, Rabat, Marrakech, Fes, Tanger, Agadir
ğŸ”§ Capteurs : 20
ğŸ“¡ Topic Kafka : iot-temperature
============================================================
âœ… 10 messages envoyÃ©s - Dernier: Marrakech 26.79Â°C
âœ… 20 messages envoyÃ©s - Dernier: Agadir 32.15Â°C
```

### Terminal 2 : Lancer Spark Streaming
```powershell
docker exec -it spark-master /opt/spark/bin/spark-submit --master local[2] --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 /opt/spark-apps/consumer_spark.py
```

**Sortie attendue :**
```
======================================================================
ğŸš€ SPARK STREAMING - MONITORING IoT
======================================================================
âœ… Pipeline actif !
ğŸ“Š Console : DonnÃ©es brutes (10s)
ğŸ“ˆ Console : AgrÃ©gations (30s)
ğŸ’¾ HDFS : /tmp/iot-data/raw
```

### Laisser Tourner 2-3 Minutes

Les deux terminaux doivent rester actifs pour collecter des donnÃ©es.

### ArrÃªter les Processus

Appuyez sur **Ctrl+C** dans chaque terminal (producteur et consumer).

### Terminal 3 : Lancer l'Analyse
```powershell
docker exec -it spark-master /opt/spark/bin/spark-submit --master local[2] /opt/spark-apps/analysis.py
```

### RÃ©cupÃ©rer le Rapport
```powershell
docker cp spark-master:/tmp/rapport.md ./rapport_final.md
```

---

## ğŸ“Š RÃ©sultats

### MÃ©triques de Performance

| MÃ©trique | Valeur |
|----------|--------|
| **Messages traitÃ©s** | 200+ |
| **Villes surveillÃ©es** | 6 |
| **Capteurs actifs** | 20 |
| **Latence moyenne** | < 10 secondes |
| **Fichiers Parquet gÃ©nÃ©rÃ©s** | 30+ |
| **Format de compression** | Snappy |

### Exemple de DonnÃ©es CollectÃ©es
```
+----------+----------+-----------+--------+--------------------------+
|sensor_id |city      |temperature|humidity|timestamp                 |
+----------+----------+-----------+--------+--------------------------+
|SENSOR_003|Casablanca|32.45      |67.8    |2025-12-28 20:15:12       |
|SENSOR_012|Marrakech |26.79      |45.2    |2025-12-28 20:15:13       |
|SENSOR_007|Rabat     |29.34      |58.6    |2025-12-28 20:15:14       |
+----------+----------+-----------+--------+--------------------------+
```

### AgrÃ©gations par Ville
```
+----------+------------------+--------+--------+------------+
|city      |avg_temp          |max_temp|min_temp|num_readings|
+----------+------------------+--------+--------+------------+
|Marrakech |33.45             |44.2    |18.5    |45          |
|Casablanca|31.23             |42.8    |16.3    |52          |
|Agadir    |29.87             |39.5    |19.2    |38          |
+----------+------------------+--------+--------+------------+
```

### Alertes DÃ©tectÃ©es

- ğŸ”¥ **TempÃ©ratures > 40Â°C :** 23 occurrences
- â„ï¸ **TempÃ©ratures < 20Â°C :** 18 occurrences

---

## ğŸ“ Structure du Projet
```
bigdata-project/
â”œâ”€â”€ docker-compose.yml          # Configuration Docker
â”œâ”€â”€ README.md                   # Ce fichier
â”œâ”€â”€ rapport_bigdata_iot.tex     # Rapport LaTeX
â”œâ”€â”€ data/                       # (vide - donnÃ©es temporaires)
â””â”€â”€ scripts/
    â”œâ”€â”€ producer.py             # Producteur Kafka
    â”œâ”€â”€ consumer_spark.py       # Consumer Spark Streaming
    â””â”€â”€ analysis.py             # Analyse finale
```

### Description des Scripts

#### 1. `producer.py`

Simule 20 capteurs IoT envoyant des donnÃ©es de tempÃ©rature et d'humiditÃ© Ã  Kafka.

**FonctionnalitÃ©s :**
- GÃ©nÃ©ration alÃ©atoire de tempÃ©rature (15-45Â°C)
- GÃ©nÃ©ration alÃ©atoire d'humiditÃ© (20-90%)
- Envoi Ã  Kafka toutes les 1 seconde
- 6 villes diffÃ©rentes

#### 2. `consumer_spark.py`

Consumer Spark Streaming qui traite les donnÃ©es en temps rÃ©el.

**FonctionnalitÃ©s :**
- Lecture depuis Kafka
- AgrÃ©gations par fenÃªtres de 30 secondes
- Affichage console (donnÃ©es brutes + agrÃ©gations)
- Sauvegarde HDFS en format Parquet

#### 3. `analysis.py`

Script d'analyse batch des donnÃ©es stockÃ©es.

**FonctionnalitÃ©s :**
- Lecture des fichiers Parquet
- Calcul de statistiques par ville
- DÃ©tection d'alertes (tempÃ©ratures extrÃªmes)
- GÃ©nÃ©ration de rapport Markdown

---

## ğŸŒ Interfaces Web

- **Spark Master UI :** http://localhost:8080
- **Spark Application UI :** http://localhost:4040
- **HDFS NameNode UI :** http://localhost:9870

---

## ğŸ”§ DÃ©pannage

### ProblÃ¨me : Conteneurs ne dÃ©marrent pas
```powershell
docker-compose down
docker system prune -f
docker-compose up -d
```

### ProblÃ¨me : Permissions Ivy Cache
```powershell
docker exec -it -u root spark-master bash -c "mkdir -p /home/spark/.ivy2/cache && chown -R spark:spark /home/spark/.ivy2 && chmod -R 777 /home/spark/.ivy2"
```

### ProblÃ¨me : Topic Kafka existe dÃ©jÃ 
```powershell
docker exec -it kafka kafka-topics --delete --topic iot-temperature --bootstrap-server localhost:9092
```

---

## ğŸ“š RÃ©fÃ©rences

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Apache Spark Streaming Guide](https://spark.apache.org/docs/latest/streaming-programming-guide.html)
- [Hadoop HDFS Architecture](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)

---

## ğŸ‘¨â€ğŸ’» Auteur

**ELARBI ALLAM**  
Ã‰tudiant en Big Data  
ENSA - 2025/2026

---

## ğŸ“„ Licence

Ce projet est rÃ©alisÃ© dans le cadre d'un travail pratique universitaire.

---

**DerniÃ¨re mise Ã  jour :** DÃ©cembre 2025